# -*- coding: utf-8 -*-
"""Data Scientist.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w0LrX6tIqxKR3z0mrdEEORTTQFSlJxeD

## Tahap 1: Pemahaman Masalah & Problem Statement

### Problem Statement
"""

# Prediksi Nilai Transaksi
## - Bagaimana cara memprediksi Total Price berdasarkan kategori, subkategori, aksi user, dan informasi lain yang tersedia?
## - Model prediktif ini akan membantu memperkirakan potensi revenue dari interaksi user.
# Faktor yang Mempengaruhi Nilai Transaksi
## - Fitur apa saja yang paling memengaruhi Total Price?
## - Seberapa besar kontribusi masing-masing faktor?

"""### Tujuan Proyek"""

# - Mengembangkan model prediksi Total Price yang akurat dan andal.
# - Mengidentifikasi faktor-faktor penting yang berpengaruh terhadap Total Price.
# - Memberikan rekomendasi bisnis berdasarkan hasil analisis, misalnya strategi upselling, fokus kategori tertentu, atau peningkatan customer engagement di aksi tertentu (add_to_cart → purchase).

"""## Tahap 2: Data Preprocessing"""

import pandas as pd
import numpy as np

# Load data
df = pd.read_excel("/content/final_customer_data.xlsx")
print("Data: ", df.head())

"""### Struktur Data"""

print("Ukuran Dataset: ",df.shape)

print("Informasi Dataset: ", df.info())

print("Statistik Deskriptif: ", df.describe())

"""### Pembersihan Data

#### Missing Value
"""

print("Missing values:\n", df.isnull().sum())

# Isi missing values
for col in ['Quantity', 'Rate', 'Total Price']:
    df[col] = df[col].fillna(df[col].median())
for col in ['Category', 'SubCategory', 'Action']:
    df[col] = df[col].fillna(df[col].mode()[0])

"""#### Data Duplikat"""

# Hapus duplikat
df = df.drop_duplicates()

"""### Transformasi Data"""

# Ubah DateTime ke format datetime
df['DateTime'] = pd.to_datetime(df['DateTime'], errors='coerce')

from sklearn.preprocessing import LabelEncoder, StandardScaler

# Encoding kategorikal
le = LabelEncoder()
for col in ['Category','SubCategory','Action']:
    df[col] = le.fit_transform(df[col])

# Buang ID
df = df.drop(['User_id','Session_id'], axis=1)

# Feature engineering dari DateTime
df['hour'] = df['DateTime'].dt.hour.fillna(0).astype(int)
df['dayofweek'] = df['DateTime'].dt.dayofweek.fillna(0).astype(int)
df['month'] = df['DateTime'].dt.month.fillna(0).astype(int)

df = df.drop(columns=['DateTime'])

# Split fitur dan target
X = df.drop(columns=['Total Price'])
y = df['Total Price']

# Standarisasi numerik
scaler = StandardScaler()
num_cols = ['Quantity','Rate','hour','dayofweek','month']
X[num_cols] = scaler.fit_transform(X[num_cols])

"""Interpretasi:
- Missing values diisi median data.
- Variabel kategorikal (Category, SubCategory, Action) di-encode.
- Variabel waktu dipecah menjadi jam, hari dan bulan.
- Dataset bersih & siap modeling.

## Tahap 3: Pengembangan Model

### Pembagian Dataset
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""### Pemilihan Model"""

models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(random_state=42, n_jobs=-1),
    "XGBoost": XGBRegressor(random_state=42, verbosity=0)
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    # Calculate RMSE by taking the square root of MSE
    rmse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    results[name] = {"MAE": mae, "RMSE": np.sqrt(rmse), "R²": r2}

    # Plot prediksi vs actual
    plt.scatter(y_test, y_pred, alpha=0.5)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    plt.xlabel("Actual Total Price")
    plt.ylabel("Predicted Total Price")
    plt.title(f"{name} - Actual vs Predicted")
    plt.show()

results_df = pd.DataFrame(results).T
print(results_df)

"""Interpretasi:
- Visualisasi Actual vs Predicted
  - Linier Regression
    - Pola titik lebih menyebar merata di sekitar garis merah. Model cenderung underpredict nilai tinggi juga, tetapi secara keseluruhan titik-titik lebih “mengikuti” garis merah dibanding Decision Tree.
  - Desion Tree
    - Banyak titik menumpuk di bawah garis merah pada nilai tinggi artinya prediksi Decision Tree cenderung underpredict (terutama untuk harga tinggi). Namun pada harga rendah, model cukup tepat (titik-titik dekat garis merah).
  - Random Forest
    - Banyak titik jauh di atas garis merah di nilai actual yang besar artinya model cenderung overestimate pada harga besar.
  - XGBoost
    - sebaran lebih mendekati garis merah, walau ada beberapa outlier → lebih stabil dibanding Random Forest pada harga besar.
- Tabel Metrik
  - Linear Regression punya R² tertinggi (0.913) artinya model ini paling baik menjelaskan variasi total price.
  - Decision Tree punya MAE terendah (168) artinya prediksinya rata-rata paling dekat dengan aktual, meskipun R² lebih rendah.
  - Random Forest justru performa terburuk di sini (R²=0.708, RMSE paling tinggi) artinya kemungkinan model overfit atau kurang optimal di hyperparameter-nya.
  - XGBoost lebih baik daripada Random Forest di RMSE dan R².

## Tahap 4: Optimasi Model

### Hyperparameter tuning Random Forest
"""

from sklearn.model_selection import GridSearchCV, KFold, cross_val_score

# Hyperparameter tuning Random Forest
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5]
}

grid_rf = GridSearchCV(
    RandomForestRegressor(random_state=42),
    param_grid, cv=5, scoring='r2', n_jobs=-1
)
grid_rf.fit(X_train, y_train)

print("Best params RF:", grid_rf.best_params_)
print("Best CV score RF:", grid_rf.best_score_)

"""### Validasi Silang"""

# Validasi silang pada model terbaik
kf = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(grid_rf.best_estimator_, X, y, cv=kf, scoring='r2')
print("Cross-val R² mean:", np.mean(cv_scores))



"""Interpretasi:
- Nilai R² = 0.889 pada fold terbaik menunjukkan model Random Forest bisa menjelaskan sekitar 88,9 % variansi target pada data validasi di fold itu.
- Nilai rata-rata R² = 0.821 menunjukkan bahwa, secara keseluruhan, pada data yang belum dilihat model, Random Forest mampu menjelaskan sekitar 82,1 % variansi target.
- Adanya selisih antara nilai terbaik dan nilai rata-rata menunjukkan performa model cukup stabil, karena tidak turun drastis di fold lain.
"""

# Faktor yang paling berpengaruh
## Linear Regression Coefficients
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.linear_model import LinearRegression

linreg = LinearRegression()
linreg.fit(X_train, y_train)

coef_df = pd.DataFrame({
    "Feature": X.columns,
    "Coefficient": linreg.coef_
}).sort_values(by="Coefficient", key=abs, ascending=False)

plt.figure(figsize=(8,5))
sns.barplot(data=coef_df, x="Coefficient", y="Feature", palette="viridis")
plt.title("Linear Regression - Feature Coefficients")
plt.show()

print("Koefisien Linear Regression:")
print(coef_df)

## Feature Importances dari Tree-based Models
def plot_feature_importance(model, model_name):
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]

    plt.figure(figsize=(8,5))
    sns.barplot(x=importances[indices], y=X.columns[indices], palette="mako")
    plt.title(f"{model_name} - Feature Importances")
    plt.show()

    return pd.DataFrame({
        "Feature": X.columns[indices],
        "Importance": importances[indices]
    })

# Train tree-based models
dt = DecisionTreeRegressor(random_state=42).fit(X_train, y_train)
rf = RandomForestRegressor(random_state=42, n_jobs=-1).fit(X_train, y_train)
xgb = XGBRegressor(random_state=42, verbosity=0).fit(X_train, y_train)

# Plot feature importances
fi_dt = plot_feature_importance(dt, "Decision Tree")
fi_rf = plot_feature_importance(rf, "Random Forest")
fi_xgb = plot_feature_importance(xgb, "XGBoost")

print("Decision Tree Feature Importances:")
print(fi_dt)
print("\nRandom Forest Feature Importances:")
print(fi_rf)
print("\nXGBoost Feature Importances:")
print(fi_xgb)

"""Interpretasi:
- Linear Regression coefficients + feature importances tree-based menunjukkan fitur seperti:
  - Rate (harga per unit),
  - Quantity,
  - Kategori & Subkategori,
  - serta aksi user tertentu (misalnya add_to_cart → purchase) merupakan faktor dominan memengaruhi Total Price.

# Kesimpulan
- Linear Regression tetap yang paling baik menjelaskan variansi target di data ini (R² ~0.91).
- Random Forest setelah tuning mendekati performa baik (R² mean CV ~0.82) tapi masih di bawah Linear Regression.
- Decision Tree lebih tepat untuk prediksi sederhana dengan kesalahan rata-rata kecil, tapi kurang baik menjelaskan variansi.
- XGBoost cukup stabil di nilai tinggi, jadi bisa jadi alternatif selain RF.

# Saran & Rekomendasi Bisnis
1. Fokus pada Variabel yang Paling Berpengaruh
    - Rate (harga per unit) dan Quantity adalah faktor terbesar pembentuk Total Price. Artinya, dorong strategi upselling / bundling (contoh: tawarkan diskon untuk pembelian >1 unit agar quantity naik).
    - Kategori & Subkategori tertentu menghasilkan transaksi lebih tinggi. Artinya, prioritas stok, promosi, dan kampanye marketing pada kategori/subkategori yang rata-rata transaksinya besar.
2. Segmentasi Pelanggan untuk Penawaran Tepat Sasaran
   - Gunakan prediksi Total Price untuk mengelompokkan user dengan potensi belanja tinggi vs rendah. Artinya, tawarkan loyalty rewards, diskon premium, atau cross-selling khusus user bernilai tinggi.
3. Pengendalian Harga & Promosi
   - Karena Rate berpengaruh kuat, penetapan harga yang tepat bisa langsung mempengaruhi revenue. Artinya, lakukan price testing / dynamic pricing di kategori utama untuk melihat sensitivitas harga.
4. Prioritaskan Sumber Daya Marketing
   - Dengan model prediksi ini, tim marketing bisa memfokuskan budget pada interaksi dan kategori dengan prediksi Total Price tinggi.
   - Campaign lebih efisien karena diarahkan ke user dengan potensi revenue besar.
"""